{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bdcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "from gym_recorder import Recorder\n",
    "#pip install gym_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a290db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Game being used\n",
    "env = gym.make('LunarLander-v2')# -> gym.openai.com/#envs\n",
    "env = Recorder(env, episode_num=10)\n",
    "states = env.observation_space.shape[0]\n",
    "\n",
    "#Number of actions available.\n",
    "actions = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0495ff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\rl\\agents\\ddpg.py:9: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "from keras import __version__\n",
    "tf.keras.__version__ = __version__\n",
    "\n",
    "from rl.agents import SARSAAgent #check diferent agents -> https://keras-rl.readthedocs.io/en/latest/\n",
    "from rl.agents import DQNAgent #check diferent agents -> https://keras-rl.readthedocs.io/en/latest/\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "def build_model(states, actions):\n",
    "    model = Sequential() \n",
    "    model.add(Flatten(input_shape=(1,) + env.observation_space.shape)) \n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dense(actions,activation='linear'))     \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_agent(model, actions):\n",
    "    policy = EpsGreedyQPolicy()\n",
    "    #earlystop = EarlyStopping(monitor = 'episode_reward', min_delta=.1, patience=5, verbose=1, mode='auto') \n",
    "    memory = SequentialMemory(limit=1000000,window_length=1)\n",
    "    #callbacks = [earlystop] \n",
    "    nb_steps_warmup = 1000 \n",
    "    target_model_update = .2 \n",
    "    gamma = .99 \n",
    "    #epochs = training_steps/1000 \n",
    "    #decay = float(lr/epochs) \n",
    "    dqn = DQNAgent(model=model, nb_actions=actions, memory=memory, nb_steps_warmup=nb_steps_warmup, target_model_update = target_model_update, policy=policy, gamma = gamma)\n",
    "    return dqn\n",
    "\n",
    "model = build_model(states,actions.n)\n",
    "\n",
    "dqn = build_agent(model,actions.n)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ff8c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 2 episodes ...\n",
      "WARNING:tensorflow:From C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2595: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\keras\\src\\engine\\training_utils_v1.py:50: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge Mimoso\\anaconda3\\envs\\LunarLander\\Lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward: 283.727, steps: 238\n",
      "Episode 2: reward: 293.585, steps: 220\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dqn.load_weights('trained weights/LunarLander-v2_weights2000000.h5f')\n",
    "_ = dqn.test(env, nb_episodes=2, visualize=True)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69108e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6d9d2-9626-446a-9dcf-75700c75afc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
